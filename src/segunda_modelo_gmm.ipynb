{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segunda parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "#x = np.linspace(0,2*np.pi,100)\n",
    "#y = np.sin(x) + np.random.random(100) * 0.2\n",
    "yhat = scipy.signal.savgol_filter(Y, 51, 3) # window size 51, polynomial order 3\n",
    "plt.plot(x,Y)\n",
    "plt.plot(x,yhat, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siendo un modelo probabilístico se pueden aplicar métricas como el Akaike information criterion\n",
    "(AIC) o Bayesian information criterion (BIC) para identificar cómo se van ajustando los\n",
    "datos observados al modelo. Cabe aclarar que en ambas métricas, cuanto más bajo sea el valor es\n",
    "mejor. Por lo que se prueba para revisar el modelo con un rango de 1 a 10 como valores del nro de\n",
    "componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se entrena modelos con 1-10 componentes\n",
    "Y_copy = Y.copy()\n",
    "Y_copy = Y_copy.reshape(-1,1)\n",
    "N = np.arange(1, 11)\n",
    "models = [None for i in range(len(N))]\n",
    "for i in range(len(N)):\n",
    "    models[i] = GaussianMixture(N[i]).fit(Y_copy)\n",
    "#se calcula AIC y BIC\n",
    "AIC = [m.aic(Y_copy) for m in models]\n",
    "BIC = [m.bic(Y_copy) for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se grafica los resultados\n",
    "#fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(\n",
    "fig.subplots_adjust(left=0.12, right=0.97,\n",
    "    bottom=0.21, top=0.9, wspace=0.5)\n",
    "    \n",
    "#grafico 1\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(N, AIC, '-k', label='AIC')\n",
    "ax1.plot(N, BIC, '--k', label='BIC')\n",
    "ax1.set_xlabel('nro componentes')\n",
    "ax1.set_ylabel('informacion')\n",
    "ax1.legend(loc=2)\n",
    "    \n",
    "#grafico 2\n",
    "# plot 1: data + best-fit mixture\n",
    "ax2 = fig.add_subplot(122)\n",
    "M_best = models[np.argmin(AIC)]\n",
    "    \n",
    "x_best = np.linspace(600,900, 1000)\n",
    "logprob = M_best.score_samples(x_best.reshape(-1, 1))\n",
    "responsibilities = M_best.predict_proba(x_best.reshape(-1, 1))\n",
    "pdf = np.exp(logprob)\n",
    "pdf_individual = responsibilities * pdf[:, np.newaxis]\n",
    "    \n",
    "#ax2.hist(Y_copy,bins=100, density=True, histtype='stepfilled', alpha=0.4)\n",
    "#ax2.plot(x,Y_copy,color='r')\n",
    "ax2.plot(x_best, pdf, '-k')\n",
    "ax2.plot(x_best, pdf_individual, '--k')\n",
    "ax2.text(0.04, 0.96, \"Best-fit Mixture\",\n",
    "    ha='left', va='top', transform=ax2.transAxes)\n",
    "ax2.set_xlabel('$x$')\n",
    "ax2.set_ylabel('$p(x)$')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
